
EC2 : Elastic Compute Cloud : Server class :  Region specific service

Instance = Server = Azure VM = Compute engine = box

Client Class OS : Win7, win10, Windows11, ubuntu Desktop ==> EC2 wont support.
Server Class OS : Windows server 2008 r2, 2012, 2012 r2, 2016, 2019, RHEL, Amazon Linux 2/2023.

On-Demand ec2 instances : When we have unpredictable workloads.. Testing our application for the firsttime.. "FREE TIER ELIGIBILITY"
Pricing : /Sec (With min of 60 Sec)

Reserved ec2 instances : When out workload is stable and predictable.. For longer durations.. We can reserve the capacity for 1yr/3yr.. "NO FREE TIER ELIGIBILITY".

	Standard RI : We cannot change config during the period. 
	Convertable RI : We can change the config during the period.
	Scheduled RI : if we have persistant/repeated requests. (N V)

Pricing : 
Full Upfront : Pay 100% as onetime. 
Partial upfront : Pay 30-50% as onetime, Then remaining amount pay monthly basis with redused hourly price, based on usage.
No upfront : Pay everything monthly basis. 
--> AWS Marketplace : We can sell our resources. 

Spot instances : When we have flexible start/stop durations.. No Critical data/application is delivering..!!  Test env.. Bid your price against AWS pricing. If our quoted price is euqual or greater than aws pricing, we will get the instance.
--> high confi server at low cost for temp requ.
"NO FREE TIER ELIGIBILITY"
--> quoted price is euqual or greater than aws pricing, we will get the instance.
--> If price increased, AWS will terminate(delete) our instance.


1 hr 50 Min : Price increased, AWS Terminated our Instance : 1 Hr
1 hr 50 Min : Price not increased, You Terminated our Instance : 1 Hr 50 Min

=======================================================================================

Windows ec2 instance launch : 

Step 1 : Choose an AMI (Amazon Machine Image)	: Operating System : Windows server 2016 base

Step 2 : Choose an Instance type 		: vCPU, Memory(RAM), Network perf
==> t2.micro


General Purpose : Stable/balanced performance of compute, memory and network resources.
Type : t2, t3, t4, m5

Compute Optimized : We will get more CPU performances from these instances. We will have high perf processors in these instances.
Type : c4, c5, c6  (Compute / CPU)

Memory Optimized : We will get more RAM perf. Workloads required to process large set of data via memory.
Type : r4, r5, r6, x1, z1, u1 (RAM)

GPU Optimized / Accelerated computing : We will get more graphic processings, Efficient for data pattern matching, High level gaming.
Type : p2, p3, p4, g3, g4, f1

Storage optimized : we will get more Storage/ Hard Disk performance. FOr the application required more IOPS, we use this types.
Type : d2, d3, i3

c5.xlarge	: 4 cpu, 8 ram **
c5.2xlarge	: 8 cpu, 16 ram ***
m5.large	: 2 CPU, 8 RAM
t4g.medium	: 2 cpu, 4 ram

Maintenance windows : Sat 03 AM IST.. : Greenzone window : CRQ (Change Request)
-> Implementaiton Plan : What changes you are applying and how.
-> Validations : Changes status, Success/failed/issues.
-> Roll Back plan : If any issue, how ca we get it to previous state.

Step 3 : Configure additional settings
	VPC, ROles, userdata

	Instance Termination protection : Enable (Protect against accidental termination)
	Shutdown behaviour : STOP

Step 4 : Choose storage

	root volume : volume that contains Operating system : 30 gb for windows

Step 5 : Add Tags : COmbination of Key and Value pairs.

Name : 
Project : 
Platform : Windows / Linux
COst center : AAZAA

Step 6: Configure Security Group : Security group acts as Firewall at Instance level.

OS Ports/protocols : 0 - 65535

Windows : RDP : 3389 : 
Linux : SSH : 22
Webserver : http : 80
Secure web : https : 443
mysql : 3306
mssql : 1433
NFS : 2049

source : From where you want to connect to this instance.
MyIP : It picks currently connected network ip address. No one can connect to the server apart from this particular network users.
Custom : We can give any network IPs. 
Anywhere : Anyone with valid credentials can connect to the server. (username and pwd)

Step 7 : Review and launch with keypair.

Keypair : Key pair contains public key and private key. (.pem)

AWS Holds the Public Key. This will be stored in our launched ec2 instances.
Customer/WE holdes the Private key. Used to decrypt/generate the password for initial instance connect.

Public IP : Unique across the globe : Use this to connect to your instance.
Private IP : Unique with in the aws network : 

COnnect to Windows Instance :

--> Open "run" , type "mstsc" , CLick enter.. Provide instance "Public IP".
--> Choose instance "connect', choose "RDP Client", "Download remote desktop file"

MAC : https://apps.apple.com/us/app/microsoft-remote-desktop/id1295203466?mt=12


start/stop : 10 days work.. 1 month.. : Stop, Start the server
Terminate : Delete the server..


Windows : No addl softwares required..  Click on start --> search "remote desktop connection"
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

==> open run (Windows Key + R) --> type "mstsc"
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

==> Select Instance, Click on "connect" and Select "RDP Client", click on "Download remote desktop file", open the downloaded file.


Mac : Goto appstore --> search for "microsoft remote desktop" software.
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

________________________

Task : Launch windows ec2 instance and using keypair get connect to ec2 instance.

Task 2 : Change the password of "Administrator", Disconnect from the instance. Now try to login to ec2 instance using "keypair pwd", "Custom password".

Task 3 : With in this ec2 instance "Create a new user" in ec2 instance and provide him "Local administrator rights", also provide him "Remote desktop permissions".. 

Task 4 : Once Task 3 completed, Try to Take a session with task3 user.


=======================================================================================

D: 27/08/2024

Linux OS : Amazon Linux 2 OS.. RHEL, Ubuntu, Suse, Kali

RedHat, CentOS --> Amazon Linux 

Step 1 : Choose an AMI (Amazon Machine Image)	: Operating System : Amazon Linux 2 
	
Step 2 : Choose an Instance type : t2.micro	: vCPU, Memory(RAM), Network perf

Step 3 : Configure additional settings
	VPC, ROles, userdata

	Instance Termination protection : Enable
	Shutdown behaviour : STOP

Step 4 : Choose storage

	root volume : volume that contains Operating system : 8/10 gb for linux

Step 5 : Add Tags : COmbination of Key and Value pairs.

Name : 
Project : 
Platform : Windows / Linux
Cost center : AAZAA

Step 6: Configure Security Group : Security group acts as Firewall at Instance level.

Linux : SSH : 22 : Anywhere
Webserver : http : 80
Secure web : https : 443

Step 7 : Review and launch with keypair.

Keypair : Key pair contains public key and private key. (.pem)

===========
browser-method
===========

How to Connect to Linux Instance :

--> Select Instance, click on "Connect" --> "ec2 instance connect" --> "ec2-user" --> Connect. (We don't use this in realtime)

===========
Windows Command prompt with openssh
===========

--> We can use windows Cmd prompt to connect to Linux Instance : Install "OpenSSH" in your laptop. 
	--> apps&features --> optional features --> openssh client--> Enable/Install.

==> https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse

==> ssh -i keypair.pem ec2-user@publicip/dns
ssh -i "linuxkp.pem" ec2-user@ec2-3-108-53-198.ap-south-1.compute.amazonaws.com

__

Enabling SSH in your windows 10 /11 laptops.

https://learn.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse?tabs=gui#install-openssh-for-windows

===========
Putty method
===========

Putty : Putty Don't support .pem format files.. Putty need .ppk (putty private key) file format. 
1 --> generate a .ppk file, before launching linux instance and use the .ppk file to connect using putty application.
2 --> Convert the existing .pem file to .ppk file using PuttyGEN application. 

https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html	--> Download putty

__

===========
GIT Method
===========

Install "GIT for Windows", Then use GIt terminal to connect. 

https://git-scm.com/download/win

--> go to the location where we have the keypair, "Git Bash here"


Bad Permissions error :  chmod 400 keypairname.pem  (Works with GIT for Windows)

https://stackoverflow.com/questions/8193768/unprotected-private-key-file-error-using-ssh-into-amazon-ec2-instance-aws
___________________________

Linux Instances : Default username : ec2-user  / redhat / ubuntu


Task : Launch Linux ec2 instance and get connect to it.

===========================================================================

D: 28/08/2024

whoami		--> tells us as what user we are working.
sudo		--> allow user to execute the command with root level permissions
sudo su		--> Switch to root user
exit		--> Exit from root user to ec2-user
clear		--> Clears the screen

ls			--> List the files/folders
ll			--> long list
ls -ll		--> Longh list the files/folders from current path
ls -a		--> List all including hidden files
pwd			--> Print working directory
mkdir		--> Create a Directory/Folder
touch 		--> o bytes file/ plain file
cd			--> Change directory
cd ..		--> To come one step back from current path.
rmdir		--> remove directory, if it is empty.
rm -rf foldername/	--> Delete a directory that contains files forecefully and recursively.

copy and paste :  cp
cut and paste  :  mv

mv/cp source-file destination-path

to rename a file we use "mv" command :  mv oldfilename newfilename

_________________________

vim / vi / nano

VIM Editor : 

vim filename	--> Open this file in VIM editor

Press I			--> INSERT Mode
Press ESC		--> ReadOnly Mode
:wq				--> Write and Quit (Write changes to file and quit the editor)
:q!				--> Quit the Editor without writing the changes

set number		--> To set page numbers in VIM
set nonumber	--> To remove page numbers
dd				--> Delete the current line
10dd			--> Delete 10 lines from cursor

=====================================================================================

Task : Complete all 4 modules or, Atleast 2 modules.

https://linuxsurvival.com/

=======================================================================================

D: 29/08/2024

Req: Make this linux Instance as Web Server (Apache).

rpm : Redhat package manager
yum : Yellowdog Update manager
dnf : Update for yum

ssh : 22
RDP : 3389
http : 80
https : 443
mysql : 3306
mssql : 1433
nfs : 2049


yum install httpd -y
service httpd status			--> httpd webserver service status
service httpd start/stop/restart
chkconfig httpd on				--> Makes httpd as logon service.

path : /var/www/html/

cd /var/www/html/

use vim and create a file with "index.html" name in /var/www/html/ path to deliver it as default webpage.

apache logs store in this location : /var/log/httpd/ (access_log and error_log)

Apache configuration path : /etc/httpd/conf/httpd.conf  ==> edit this file "LISTEN 80", change it to desired port number.. "LISTEN 8080", Save and Quit
--> Open port 8080 at Security group level.

==> make sure you restart the service to take changes effect.


to check web page on modified port : curl http://publicip:8080/

We get 2 types of errors..
1. Timeout : Your req not able to reach the web server. problem with Security group.
2. Connection refused : Service is not in running state. Verify status by running "service httpd status"


Task 1 : Launch an amazon linux 2, make it as webserver and deliver custom web content. (httpd-apache)

Task 2 : Once task 1, completed. Change apache configuration port from 80 to 8888/8080 and Delive same webpage on 8888/8080 port.

Task 3 : Launch an Amazon Linux 2/2023, install nginx and deliver custom web page.

================================================================================================

yum install httpd -y
service httpd start
chkconfig httpd on

cd /var/www/html/

vim index.html  <h1> Sample Data </h1>

service httpd status/stop/restart

To change Apache default port number, navigate to the configuration path (/etc/httpd/conf) and edit the httpd.conf file. (vim httpd.conf)
At Line 47, You can see LISTEN 80, Change it to desired port number.

We did a config change, we have to restart the service.

service httpd restart

13.235.45.41:8888


=========================================================================================================

How to deal with Volumes

root volume : COntains OS : gp2,gp3, io1, io2 and magnetic

IOPS : Input and output Operations per second

GP2, Gp3 : general Purpose :SSD: Suitable for most of the common workloads.
io1, io2 : Provisional IOPS :SSD: Gives best perf among all storage options. 
sc1 ($), st1($$) : HDD : wont support boot/root volume : Best throughput values. : log processing/bigdata/Data Warehousing
magnetic : standard : We dont use this.. : Cheapest storage 

Windows : FAT, NTFS and ReFS
Linux : ext3, ext4, xfs

EBS : Elastic Bloc Storage : Block based storage : Designed to run OS.. 

root : SSD and magnetic is supported.
Addl volume : SSD, HDD and magnetic

Step: CHoose Storage

--> EBS : Elastic Block Storage
SSD / HDD / Magnetic


root Volume : COntains OS : gp2, gp3, io1, io2 and standard/magnetic
Additional volume : all root supported + st1, sc1

General Purpose SSD : (gp2 / gp3) : Low latency interactive applications, Dev and test environment..!!
Min : 1 GiB, Max: 16 TiB... Max IOPS: 16,000 IOPS
gp2 --> works 1 : 3 ration (1 gb volume = 3 iops), with min of 100..

for gp3, we have an advantage, we can mention/choose required IOPS count.

__

Provisioned iops : (io1 & io2) : workload that requires Specific IOPS count.. or if we need more than 16,000 iops for our ec2 instance.. I/O Intensive database workloads..
Min : 4 GiB, Max: 16 TiB... Max IOPS: 64,000 IOPS
--> It provided highest performance among all. 

io2 Block Express volume : Min : 4 GiB, Max: 64 TiB...
Supports 256,000 IOPS.. 
__

Magnetic : Standard : Less freq accessed data, Low cost storage solutions.. 
Min : 1 GiB, Max: 1 TiB...
__

Throughput optimized HDD : st1 : Bigdata, Data warehousing, log processing.. 
Size : Min 125 GiB - 16 TiB.. IOPS : 500.. Throughput : 500 MB/S..

Cold HDD : sc1 : THroughput orientes storages, but with Less Frequently accessed.. Lower cost than st1.. 
Size : Min 125 GiB - 16 TiB.. IOPS : 250.. Throughput : 250 MB/S..


Free Tier : 30 gb Gp2 and standard storage.. 


--> 20% of volume size (or) 5 gb.. WHichever is highest

** Need to perform OS level operations to make additional volumes available.
--> Disk Management --> diskmgmt.msc --> choose volume --> make it online --> Initilize disk --> SImple volume --> NTFS/FAT --> Create


Windows : FAT, FAT32, NTFS, ReFS
Linux : ext3, ext4, xfs


grab the name of new volume : /dev/xvdb

lsblk		--> List block based devices
df -Th		--> List the available volumes

/dev/xvda1	--> root volume (/)
/dev/xvdf	--> new Volume name 

In windows OS, we mount new volumes to drive letters.. But in Linux OS, We mount volumes to Directory. 

mkdir newvolume

file -s /dev/xvdf  	--> If this command returns with "data", no file system.
			--> If this returns ext3/xfs filesystem.. We have a file system.


mkfs -t xfs /dev/xvdf		--> Make file system and write it to Additonal volume

mount /dev/xvdf newvolume/	--> mount addl volume to directory


=================


--> Above mount is temp mount only.. it won't available after the instance reboot.
--> To make this volume perm mount to the directory, Add entry in "/etc/fstab" file.
--> Get the entry information from "/etc/mtab" file. 

--> cat /etc/mtab		--> Grab the entry related to newly added addl volume

/dev/xvdb /home/ec2-user/2gbvol xfs rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota 0 0

--> vim /etc/fstab.. Write the above entry, save and quit the editor. (Do not edit the existing entry).

mount -all
__________

--> Increase the volume size the "Cosole" first, then execute the below command..!!

We can use "xfsprogs" to increase existing volume size. 

yum install xfsprogs

--> xfs_growfs -d /volume-Mountpoint
--> xfs_growfs -d /home/ec2-user/newvolume

--> Increasing volume is possible, But redusing volume is not possible.

===========================================================================

Task 1 : 
-> Launch an ec2 instance, 
-> Create a 2 gb additional volume, associate it with ec2 instance.. 
-> Make 2 gb volume available at os level and write some data into it. (Reboot and verify)
-> Reboot instance and enter "df -Th", 
-> Now also it should show 2gb volume with data.


Task 2 : Launch another ec2 instance in same AZ as existing ec2 instance.. Detach the volume from instance 1 and attach it to newly launched ec2 instance. Mount it to new directory. You should be able to see all the data.


==============================================================================================


rough notes :

lsblk
df -Th



Create a volume and attach to your ec2 instance, then run "lsblk" command and get name of your newly atached volume.

/dev/xvdb ==> volume name

file -s volumename => to identify file system presence.

file -s /dev/xvdb

mkfs => Command to create a file system in a volume.

mkfs -t xfs /dev/xvdb

mkdir newvol

mount ==> mount a volume to a directory

mount /dev/xvdb newvol/ 

verify it by running "lsblk" and "df -Th". 

----

To make the volume permanent mount, 

Step 1 : After mounting, get the entry from "/etc/mtab" file related to this volume.
Step 2 : Write this entry to "/etc/fstab" file.

/dev/xvdb /home/ec2-user/newvol xfs rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota 0 0

--------

To increase the volume size, First add additional starage at aws console, then increase size at OS level.

run "xfs_growfs -d /home/ec2-user/newvol/"


===========================================================================================================

D: 02/09/2024


Instance 1 in ap-south-1a ---> Instance 2 in ap-south-1a ==> Detach from instance 1 and attach to instance 2.. 

Instance 1 in ap-south-1a ---> Instance 2 in ap-south-1b ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff AZs.. 
Choose the volume --> Take a Snapshot --> Create a volume from snapshot, while creating choose ap-south-1b --> we'll get volume in 1b --> Attach to Instance 2 running in ap-south-1b

Instance 1 in Mumbai : ap-south-1a ---> Instance 2 in N Virginia : us-east-1a ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff regions.. 
Choose the volume --> Take a Snapshot --> Copy the snapshot to desired region (NV) 
--> Create a volume, while creating choose us-east-1a --> volume in 1a --> Attach to Instance 2 running in N Virginia : us-east-1a.
(Data transfer from region to region cost us)


Instance 1 in AWSACC1 : Mumbai : ap-south-1a ---> Instance 2 in AWSACC2 : Mumbai : ap-south-1a ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff aws accounts, regions.. 
Choose the volume --> Take a Snapshot --> share the snapshot to another aws account 
--> Create a volume, while creating choose ap-south-1a in acc2

Instance 1 volume need to share with everyone.. --> Create a snapshot --> Share to "Public" --> 

MultiAttach : https://www.youtube.com/watch?v=2j8R3ajSo3s

** We cannot decrease the size of an EBS volume. Only increase is possible.

EBS VOlumes : Always use EBS volumes only.

Snapshot : Backup copy of an EBS volume.

https://aws.amazon.com/blogs/storage/automating-amazon-ebs-snapshot-and-ami-management-using-amazon-dlm/


--> Snapshots are point-in-time copies.
--> Snapshots stores in S3 platform (Not in your s3).
--> Can we view what data we have inside snapshots..?? NO, WE CAN'T
--> Snapshot Works with Incremental backup mechanism. It's backend process.
--> If our volume is Encrypted, Snapshot also Encrypts automatically. 
--> When we are launching/creating a volume from encrypted snapshot, volume also encrypts automatically.
--> We cannot share an Default Master key Encrypted snapshot.
--> If we are using Custom/customer Managed encryption key, we can share snapshot with another aws account, but we need to provide permissions on encryption key also to another aws account.

Interview : How to encrypt an existing unencrypted ebs volume.?

