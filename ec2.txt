
EC2 : Elastic Compute Cloud : Server class :  Region specific service

Instance = Server = Azure VM = Compute engine = box

Client Class OS : Win7, win10, Windows11, ubuntu Desktop ==> EC2 wont support.
Server Class OS : Windows server 2008 r2, 2012, 2012 r2, 2016, 2019, RHEL, Amazon Linux 2/2023.

On-Demand ec2 instances : When we have unpredictable workloads.. Testing our application for the firsttime.. "FREE TIER ELIGIBILITY"
Pricing : /Sec (With min of 60 Sec)

Reserved ec2 instances : When out workload is stable and predictable.. For longer durations.. We can reserve the capacity for 1yr/3yr.. "NO FREE TIER ELIGIBILITY".

	Standard RI : We cannot change config during the period. 
	Convertable RI : We can change the config during the period.
	Scheduled RI : if we have persistant/repeated requests. (N V)

Pricing : 
Full Upfront : Pay 100% as onetime. 
Partial upfront : Pay 30-50% as onetime, Then remaining amount pay monthly basis with redused hourly price, based on usage.
No upfront : Pay everything monthly basis. 
--> AWS Marketplace : We can sell our resources. 

Spot instances : When we have flexible start/stop durations.. No Critical data/application is delivering..!!  Test env.. Bid your price against AWS pricing. If our quoted price is euqual or greater than aws pricing, we will get the instance.
--> high confi server at low cost for temp requ.
"NO FREE TIER ELIGIBILITY"
--> quoted price is euqual or greater than aws pricing, we will get the instance.
--> If price increased, AWS will terminate(delete) our instance.


1 hr 50 Min : Price increased, AWS Terminated our Instance : 1 Hr
1 hr 50 Min : Price not increased, You Terminated our Instance : 1 Hr 50 Min

=======================================================================================

Windows ec2 instance launch : 

Step 1 : Choose an AMI (Amazon Machine Image)	: Operating System : Windows server 2016 base

Step 2 : Choose an Instance type 		: vCPU, Memory(RAM), Network perf
==> t2.micro


General Purpose : Stable/balanced performance of compute, memory and network resources.
Type : t2, t3, t4, m5

Compute Optimized : We will get more CPU performances from these instances. We will have high perf processors in these instances.
Type : c4, c5, c6  (Compute / CPU)

Memory Optimized : We will get more RAM perf. Workloads required to process large set of data via memory.
Type : r4, r5, r6, x1, z1, u1 (RAM)

GPU Optimized / Accelerated computing : We will get more graphic processings, Efficient for data pattern matching, High level gaming.
Type : p2, p3, p4, g3, g4, f1

Storage optimized : we will get more Storage/ Hard Disk performance. FOr the application required more IOPS, we use this types.
Type : d2, d3, i3

c5.xlarge	: 4 cpu, 8 ram **
c5.2xlarge	: 8 cpu, 16 ram ***
m5.large	: 2 CPU, 8 RAM
t4g.medium	: 2 cpu, 4 ram

Maintenance windows : Sat 03 AM IST.. : Greenzone window : CRQ (Change Request)
-> Implementaiton Plan : What changes you are applying and how.
-> Validations : Changes status, Success/failed/issues.
-> Roll Back plan : If any issue, how ca we get it to previous state.

Step 3 : Configure additional settings
	VPC, ROles, userdata

	Instance Termination protection : Enable (Protect against accidental termination)
	Shutdown behaviour : STOP

Step 4 : Choose storage

	root volume : volume that contains Operating system : 30 gb for windows

Step 5 : Add Tags : COmbination of Key and Value pairs.

Name : 
Project : 
Platform : Windows / Linux
COst center : AAZAA

Step 6: Configure Security Group : Security group acts as Firewall at Instance level.

OS Ports/protocols : 0 - 65535

Windows : RDP : 3389 : 
Linux : SSH : 22
Webserver : http : 80
Secure web : https : 443
mysql : 3306
mssql : 1433
NFS : 2049

source : From where you want to connect to this instance.
MyIP : It picks currently connected network ip address. No one can connect to the server apart from this particular network users.
Custom : We can give any network IPs. 
Anywhere : Anyone with valid credentials can connect to the server. (username and pwd)

Step 7 : Review and launch with keypair.

Keypair : Key pair contains public key and private key. (.pem)

AWS Holds the Public Key. This will be stored in our launched ec2 instances.
Customer/WE holdes the Private key. Used to decrypt/generate the password for initial instance connect.

Public IP : Unique across the globe : Use this to connect to your instance.
Private IP : Unique with in the aws network : 

COnnect to Windows Instance :

--> Open "run" , type "mstsc" , CLick enter.. Provide instance "Public IP".
--> Choose instance "connect', choose "RDP Client", "Download remote desktop file"

MAC : https://apps.apple.com/us/app/microsoft-remote-desktop/id1295203466?mt=12


start/stop : 10 days work.. 1 month.. : Stop, Start the server
Terminate : Delete the server..


Windows : No addl softwares required..  Click on start --> search "remote desktop connection"
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

==> open run (Windows Key + R) --> type "mstsc"
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

==> Select Instance, Click on "connect" and Select "RDP Client", click on "Download remote desktop file", open the downloaded file.


Mac : Goto appstore --> search for "microsoft remote desktop" software.
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

________________________

Task : Launch windows ec2 instance and using keypair get connect to ec2 instance.

Task 2 : Change the password of "Administrator", Disconnect from the instance. Now try to login to ec2 instance using "keypair pwd", "Custom password".

Task 3 : With in this ec2 instance "Create a new user" in ec2 instance and provide him "Local administrator rights", also provide him "Remote desktop permissions".. 

Task 4 : Once Task 3 completed, Try to Take a session with task3 user.


=======================================================================================

D: 27/08/2024

Linux OS : Amazon Linux 2 OS.. RHEL, Ubuntu, Suse, Kali

RedHat, CentOS --> Amazon Linux 

Step 1 : Choose an AMI (Amazon Machine Image)	: Operating System : Amazon Linux 2 
	
Step 2 : Choose an Instance type : t2.micro	: vCPU, Memory(RAM), Network perf

Step 3 : Configure additional settings
	VPC, ROles, userdata

	Instance Termination protection : Enable
	Shutdown behaviour : STOP

Step 4 : Choose storage

	root volume : volume that contains Operating system : 8/10 gb for linux

Step 5 : Add Tags : COmbination of Key and Value pairs.

Name : 
Project : 
Platform : Windows / Linux
Cost center : AAZAA

Step 6: Configure Security Group : Security group acts as Firewall at Instance level.

Linux : SSH : 22 : Anywhere
Webserver : http : 80
Secure web : https : 443

Step 7 : Review and launch with keypair.

Keypair : Key pair contains public key and private key. (.pem)

===========
browser-method
===========

How to Connect to Linux Instance :

--> Select Instance, click on "Connect" --> "ec2 instance connect" --> "ec2-user" --> Connect. (We don't use this in realtime)

===========
Windows Command prompt with openssh
===========

--> We can use windows Cmd prompt to connect to Linux Instance : Install "OpenSSH" in your laptop. 
	--> apps&features --> optional features --> openssh client--> Enable/Install.

==> https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse

==> ssh -i keypair.pem ec2-user@publicip/dns
ssh -i "linuxkp.pem" ec2-user@ec2-3-108-53-198.ap-south-1.compute.amazonaws.com

__

Enabling SSH in your windows 10 /11 laptops.

https://learn.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse?tabs=gui#install-openssh-for-windows

===========
Putty method
===========

Putty : Putty Don't support .pem format files.. Putty need .ppk (putty private key) file format. 
1 --> generate a .ppk file, before launching linux instance and use the .ppk file to connect using putty application.
2 --> Convert the existing .pem file to .ppk file using PuttyGEN application. 

https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html	--> Download putty

__

===========
GIT Method
===========

Install "GIT for Windows", Then use GIt terminal to connect. 

https://git-scm.com/download/win

--> go to the location where we have the keypair, "Git Bash here"


Bad Permissions error :  chmod 400 keypairname.pem  (Works with GIT for Windows)

https://stackoverflow.com/questions/8193768/unprotected-private-key-file-error-using-ssh-into-amazon-ec2-instance-aws
___________________________

Linux Instances : Default username : ec2-user  / redhat / ubuntu


Task : Launch Linux ec2 instance and get connect to it.

===========================================================================

D: 28/08/2024

whoami		--> tells us as what user we are working.
sudo		--> allow user to execute the command with root level permissions
sudo su		--> Switch to root user
exit		--> Exit from root user to ec2-user
clear		--> Clears the screen

ls			--> List the files/folders
ll			--> long list
ls -ll		--> Longh list the files/folders from current path
ls -a		--> List all including hidden files
pwd			--> Print working directory
mkdir		--> Create a Directory/Folder
touch 		--> o bytes file/ plain file
cd			--> Change directory
cd ..		--> To come one step back from current path.
rmdir		--> remove directory, if it is empty.
rm -rf foldername/	--> Delete a directory that contains files forecefully and recursively.

copy and paste :  cp
cut and paste  :  mv

mv/cp source-file destination-path

to rename a file we use "mv" command :  mv oldfilename newfilename

_________________________

vim / vi / nano

VIM Editor : 

vim filename	--> Open this file in VIM editor

Press I			--> INSERT Mode
Press ESC		--> ReadOnly Mode
:wq				--> Write and Quit (Write changes to file and quit the editor)
:q!				--> Quit the Editor without writing the changes

set number		--> To set page numbers in VIM
set nonumber	--> To remove page numbers
dd				--> Delete the current line
10dd			--> Delete 10 lines from cursor

=====================================================================================

Task : Complete all 4 modules or, Atleast 2 modules.

https://linuxsurvival.com/

=======================================================================================

D: 29/08/2024

Req: Make this linux Instance as Web Server (Apache).

rpm : Redhat package manager
yum : Yellowdog Update manager
dnf : Update for yum

ssh : 22
RDP : 3389
http : 80
https : 443
mysql : 3306
mssql : 1433
nfs : 2049


yum install httpd -y
service httpd status			--> httpd webserver service status
service httpd start/stop/restart
chkconfig httpd on				--> Makes httpd as logon service.

path : /var/www/html/

cd /var/www/html/

use vim and create a file with "index.html" name in /var/www/html/ path to deliver it as default webpage.

apache logs store in this location : /var/log/httpd/ (access_log and error_log)

Apache configuration path : /etc/httpd/conf/httpd.conf  ==> edit this file "LISTEN 80", change it to desired port number.. "LISTEN 8080", Save and Quit
--> Open port 8080 at Security group level.

==> make sure you restart the service to take changes effect.


to check web page on modified port : curl http://publicip:8080/

We get 2 types of errors..
1. Timeout : Your req not able to reach the web server. problem with Security group.
2. Connection refused : Service is not in running state. Verify status by running "service httpd status"


Task 1 : Launch an amazon linux 2, make it as webserver and deliver custom web content. (httpd-apache)

Task 2 : Once task 1, completed. Change apache configuration port from 80 to 8888/8080 and Delive same webpage on 8888/8080 port.

Task 3 : Launch an Amazon Linux 2/2023, install nginx and deliver custom web page.

================================================================================================

yum install httpd -y
service httpd start
chkconfig httpd on

cd /var/www/html/

vim index.html  <h1> Sample Data </h1>

service httpd status/stop/restart

To change Apache default port number, navigate to the configuration path (/etc/httpd/conf) and edit the httpd.conf file. (vim httpd.conf)
At Line 47, You can see LISTEN 80, Change it to desired port number.

We did a config change, we have to restart the service.

service httpd restart

13.235.45.41:8888


=========================================================================================================

How to deal with Volumes

root volume : COntains OS : gp2,gp3, io1, io2 and magnetic

IOPS : Input and output Operations per second

GP2, Gp3 : general Purpose :SSD: Suitable for most of the common workloads.
io1, io2 : Provisional IOPS :SSD: Gives best perf among all storage options. 
sc1 ($), st1($$) : HDD : wont support boot/root volume : Best throughput values. : log processing/bigdata/Data Warehousing
magnetic : standard : We dont use this.. : Cheapest storage 

Windows : FAT, NTFS and ReFS
Linux : ext3, ext4, xfs

EBS : Elastic Bloc Storage : Block based storage : Designed to run OS.. 

root : SSD and magnetic is supported.
Addl volume : SSD, HDD and magnetic

Step: CHoose Storage

--> EBS : Elastic Block Storage
SSD / HDD / Magnetic


root Volume : COntains OS : gp2, gp3, io1, io2 and standard/magnetic
Additional volume : all root supported + st1, sc1

General Purpose SSD : (gp2 / gp3) : Low latency interactive applications, Dev and test environment..!!
Min : 1 GiB, Max: 16 TiB... Max IOPS: 16,000 IOPS
gp2 --> works 1 : 3 ration (1 gb volume = 3 iops), with min of 100..

for gp3, we have an advantage, we can mention/choose required IOPS count.

__

Provisioned iops : (io1 & io2) : workload that requires Specific IOPS count.. or if we need more than 16,000 iops for our ec2 instance.. I/O Intensive database workloads..
Min : 4 GiB, Max: 16 TiB... Max IOPS: 64,000 IOPS
--> It provided highest performance among all. 

io2 Block Express volume : Min : 4 GiB, Max: 64 TiB...
Supports 256,000 IOPS.. 
__

Magnetic : Standard : Less freq accessed data, Low cost storage solutions.. 
Min : 1 GiB, Max: 1 TiB...
__

Throughput optimized HDD : st1 : Bigdata, Data warehousing, log processing.. 
Size : Min 125 GiB - 16 TiB.. IOPS : 500.. Throughput : 500 MB/S..

Cold HDD : sc1 : THroughput orientes storages, but with Less Frequently accessed.. Lower cost than st1.. 
Size : Min 125 GiB - 16 TiB.. IOPS : 250.. Throughput : 250 MB/S..


Free Tier : 30 gb Gp2 and standard storage.. 


--> 20% of volume size (or) 5 gb.. WHichever is highest

** Need to perform OS level operations to make additional volumes available.
--> Disk Management --> diskmgmt.msc --> choose volume --> make it online --> Initilize disk --> SImple volume --> NTFS/FAT --> Create


Windows : FAT, FAT32, NTFS, ReFS
Linux : ext3, ext4, xfs


grab the name of new volume : /dev/xvdb

lsblk		--> List block based devices
df -Th		--> List the available volumes

/dev/xvda1	--> root volume (/)
/dev/xvdf	--> new Volume name 

In windows OS, we mount new volumes to drive letters.. But in Linux OS, We mount volumes to Directory. 

mkdir newvolume

file -s /dev/xvdf  	--> If this command returns with "data", no file system.
			--> If this returns ext3/xfs filesystem.. We have a file system.


mkfs -t xfs /dev/xvdf		--> Make file system and write it to Additonal volume

mount /dev/xvdf newvolume/	--> mount addl volume to directory


=================


--> Above mount is temp mount only.. it won't available after the instance reboot.
--> To make this volume perm mount to the directory, Add entry in "/etc/fstab" file.
--> Get the entry information from "/etc/mtab" file. 

--> cat /etc/mtab		--> Grab the entry related to newly added addl volume

/dev/xvdb /home/ec2-user/2gbvol xfs rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota 0 0

--> vim /etc/fstab.. Write the above entry, save and quit the editor. (Do not edit the existing entry).

mount -all
__________

--> Increase the volume size the "Cosole" first, then execute the below command..!!

We can use "xfsprogs" to increase existing volume size. 

yum install xfsprogs

--> xfs_growfs -d /volume-Mountpoint
--> xfs_growfs -d /home/ec2-user/newvolume

--> Increasing volume is possible, But redusing volume is not possible.

===========================================================================

Task 1 : 
-> Launch an ec2 instance, 
-> Create a 2 gb additional volume, associate it with ec2 instance.. 
-> Make 2 gb volume available at os level and write some data into it. (Reboot and verify)
-> Reboot instance and enter "df -Th", 
-> Now also it should show 2gb volume with data.


Task 2 : Launch another ec2 instance in same AZ as existing ec2 instance.. Detach the volume from instance 1 and attach it to newly launched ec2 instance. Mount it to new directory. You should be able to see all the data.


==============================================================================================


rough notes :

lsblk
df -Th



Create a volume and attach to your ec2 instance, then run "lsblk" command and get name of your newly atached volume.

/dev/xvdb ==> volume name

file -s volumename => to identify file system presence.

file -s /dev/xvdb

mkfs => Command to create a file system in a volume.

mkfs -t xfs /dev/xvdb

mkdir newvol

mount ==> mount a volume to a directory

mount /dev/xvdb newvol/ 

verify it by running "lsblk" and "df -Th". 

----

To make the volume permanent mount, 

Step 1 : After mounting, get the entry from "/etc/mtab" file related to this volume.
Step 2 : Write this entry to "/etc/fstab" file.

/dev/xvdb /home/ec2-user/newvol xfs rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota 0 0

--------

To increase the volume size, First add additional starage at aws console, then increase size at OS level.

run "xfs_growfs -d /home/ec2-user/newvol/"


===========================================================================================================

D: 02/09/2024


Instance 1 in ap-south-1a ---> Instance 2 in ap-south-1a ==> Detach from instance 1 and attach to instance 2.. 

Instance 1 in ap-south-1a ---> Instance 2 in ap-south-1b ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff AZs.. 
Choose the volume --> Take a Snapshot --> Create a volume from snapshot, while creating choose ap-south-1b --> we'll get volume in 1b --> Attach to Instance 2 running in ap-south-1b

Instance 1 in Mumbai : ap-south-1a ---> Instance 2 in N Virginia : us-east-1a ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff regions.. 
Choose the volume --> Take a Snapshot --> Copy the snapshot to desired region (NV) 
--> Create a volume, while creating choose us-east-1a --> volume in 1a --> Attach to Instance 2 running in N Virginia : us-east-1a.
(Data transfer from region to region cost us)


Instance 1 in AWSACC1 : Mumbai : ap-south-1a ---> Instance 2 in AWSACC2 : Mumbai : ap-south-1a ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff aws accounts, regions.. 
Choose the volume --> Take a Snapshot --> share the snapshot to another aws account 
--> Create a volume, while creating choose ap-south-1a in acc2

Instance 1 volume need to share with everyone.. --> Create a snapshot --> Share to "Public" --> 

MultiAttach : https://www.youtube.com/watch?v=2j8R3ajSo3s

** We cannot decrease the size of an EBS volume. Only increase is possible.

EBS VOlumes : Always use EBS volumes only.

Snapshot : Backup copy of an EBS volume.

https://aws.amazon.com/blogs/storage/automating-amazon-ebs-snapshot-and-ami-management-using-amazon-dlm/


--> Snapshots are point-in-time copies.
--> Snapshots stores in S3 platform (Not in your s3).
--> Can we view what data we have inside snapshots..?? NO, WE CAN'T
--> Snapshot Works with Incremental backup mechanism. It's backend process.
--> If our volume is Encrypted, Snapshot also Encrypts automatically. 
--> When we are launching/creating a volume from encrypted snapshot, volume also encrypts automatically.
--> We cannot share an Default Master key Encrypted snapshot.
--> If we are using Custom/customer Managed encryption key, we can share snapshot with another aws account, but we need to provide permissions on encryption key also to another aws account.

Interview : How to encrypt an existing unencrypted ebs volume.?


================================================================================================


SOP : Standard Operational Procedure : 
SLA : Service Level Agreements : 

DLM : Data Lifecycle manager : Automate the snapshot creation process. 
--> We use "tags" to filter the resources. 

How freq you want to take backup . 24 hrs

Default Retention Values: 
Prod : 5 Days
Non Prod : 3 Days

--> Automatically you can copy to another region (or) another aws account.

Fast snapshot restore : Enable fast snapshot restore to ensure that volumes created from snapshots created by this policy instantly deliver all of their provisioned performance.

Interview : What is your ec2 instances/services backup strategy.?

-> What service you are using.?
-> How youa re filtering/identifying resources.?
-> How frequently you taking snapshotps.?
-> What is the retention period of those Snapshots.?


============================================================================================

Tool to Move the files to amazon linux ec2 instance from Windows : "WinSCP"

--------

current IP : http://3.110.27.61/

13.127.230.20 EIP

Stop and start this instance.

--------

EIP : Elastic IP Address : If you need a dedicated/fixed IP address for your ec2 instance, you can generate an EIP and associate it.
-> EIP wont change even after performing STOP/START operation on ec2 instance.

NO FREE TIER ELIGIBILITY. IT WILL COST YOU.

ENI (Elastic Network Interface): We can allocate multiple Network Interface Cards (NICard) to a single ec2 instance.

NIC : Network interface Card
__________


Task 1 : Launch an ec2 instance in ap-south-1a.. Create a "New volume with 1 gb size" in ap-south-1a and attach this volume to ec2 instance and make it available and write some data. 
Goto AWS console "Increase the volume size to 2 GB", make this 2gb volume available at OS level. Write some data.

Task 2 : Launch Another ec2 instance in ap-south-1b..
Get the 2gb volume data from instance 1a to newly launch 1b ec2 instance.. Make Same volume available to "1b instance"..!!

Task 3 : Install WinSCP in your laptop, and connect to aws ec2 linux instance and copy some files from your local laptop to aws ec2 instance.

If you are using mac os, use "SCP" command and try to copy a file to ec2 instance.


Task 4 : Go through below article and try to understand it. https://aws.amazon.com/blogs/storage/automating-amazon-ebs-snapshot-and-ami-management-using-amazon-dlm/


============================================================================================================

D: 06/08/2024


Req : I need 10 ec2 instances, all 10 instances should have  mysql, httpd, tree, additional 2 gb volumne. 

S-1 : Launch 10 instances, connect to each and every instance and perform the required chages/installations.

S-2 : Launch 1 instance, connect to this instance and perform all installations. Then, Create a Image of this instance, From this image you can launch 9 ec2 instance. N num of instance. 


1. addl 2 gb volume and data
2. webpage 
3. install tree, mysql



==========================

*** GoldenAMI = CUstomized AMI.. Won't work with keypairs.. We need to change the password.. 

Ec2 instance , Perform customizations --> Create a Golden AMI --> From GAMI we can launch n num of ec2 instance.. 

Similar to Snapshots..

--> We can launch another instance in same region using GAMI.
--> We can copy Region 1 GAMI to Region 2, And launch an ec2 instance in Region 2. 
--> We can share GAMI from Acc 1 to Acc 2. 
--> We can share GAMI to public.

______________________________________

Task 1 : Launch Linux ec2 instance, Make it as webserver.. Add custom webpages.. Add a 2gb volume while launching and make it perm mount.. then Create a Golden AMI and 
-> Launch instance from GAMI and test output. 


Task 2 : Launch a Windows ec2 instance, Connect to it.. CHANGE ADMINISTRATOR PASSWORD, change wallpaper, install "putty" software, Install IIS and deliver custom webpage, Change timezone also..
Now, STOP the INSTANCE and create a GoldenAMi. 
-> Launch an instance from GAMI, connect and Verify you got all custom settings or not.???


Task 3 : How to setup password authentication to ec2-user user instead of keypair authentication.
https://comtechies.com/password-authentication-aws-ec2.html


================================================================================================

D: 09/09/2024


--> CloudWatch : Service to monitor all AWS resources i.e; s3, ec2, rds..
--> We can monitor CPU, Disk and network for ec2 instance.
** With Default metrics, we cannot monitor MEMORY/RAM Utilisation.
--> We can install an CloudWatch agent and monitor Memory usage as well. Additional Cost.


--> We have two types of monitorings in AWS.
==> Basic Monitoring : Free, Enabled by defaultly. 5 Minutes is monitoring interval.
==> Detailed Monitoring : COST US, Need to enable explicitlty, 1 minute is monitoring interval.

Vertical Scaling : Upgrading / Adding more resources to same Instance. i.e; from t2.micro to t3.medium

Vertical Scaling : Upgrading same instance resources.. t2.micro --> c5.2xlarge
Horizantal Scaling : Distribute application load to multiple ec2 instances.. 


To perform vertical scaling in AWS, First stop the ec2 instance, then only we can upgrqade it.


We can create alarms to get notifications via SNS, so that we can take some actions on the resources.


#!/bin/bash
yum install httpd -y
service httpd start
chkconfig httpd on
echo "<h1>This is my first webserver</h1>" > /var/www/html/index.html


#!/bin/bash
yum install httpd -y
service httpd start
chkconfig httpd on
echo "<h1>This is my Second webserver</h1>" > /var/www/html/index.html


Vertical Scaling : Upgrading same instance resources.. t2.micro --> c5.2xlarge


Task : Launch an ec2 instance, while launching pass userdata and deliver webpage.

Task 2 : Create an alarm, when Instance CPU usage is less than 30% for 10 minutes, Stop the instance and get an alart to your email.

Task 3 (optional) : Install stress package on an ec2 instance, run this stress command for 10 min.. 
Now, create an Alarm to monitor your ec2 instance cpu, when cpu usage is 80% or more for 5 min, Reboot your ec2 instance and get an alert to your email.


Real Env process : First we need to create a Change request (technical details of old conf, new config, cost diff, when you perform this(implementation window)).. Change Advisory Meeting/CAB --> once it is approved, we will implement this change.
Over weekends by taking proper downtime.  
-> We will do validations / Sanity check after upgradation.

GZ : Green Zone : Monthly 2nd weekend.. 

=========================================================================================

D: 10/09/24

Vertical Scaling : Upgrading same instance resources.. t2.micro --> c5.2xlarge
Horizantal Scaling : Distribute application load to multiple ec2 instances.. 

Classic ELB : Layer 4/7 LB.. : Outdated.. : http, https, tcp, udp.. 
Application ELB : Layer 7 ELB.. : http and https
Network ELB : Layer 4 ELB.. : TCP, UDP, TLS 
Gateway ELB : GENEVE / 3rd party security virtual applicances.. 


**Please select at least two Subnets in different Availability Zones to provide higher availability for your load balancer.

** Dont use same Security group for your ec2 instance and Load balancer.
** Use Same SG for all EC2 instances delivering same application.


For ELBs, We will get DNS Endpoint.. Not an IP Address

If you want to view IP address of an ELB, 
--> Navigate to "Network interfaces" and observe, You can get IP of ELB.
--> nslookup "ELB-DNS-NAME"


nslookup myappalb-1450403708.ap-south-1.elb.amazonaws.com


___________________________________________________

Target Group : Each target group is used to route requests to one or more registered targets. When you create each listener rule, you specify a target group and conditions. When a rule condition is met, traffic is forwarded to the corresponding target group.

Application ELB : http and https

Application Load balancing algorithm : 
--> Round robin
--> Least outstanding requests
--> Weighted ***

--> We cannot assign a dedicated IP address for our Application ELB.
--> Application LB Supports path based routing, also supports Microservices.

-----------------------

Key Diff: https://aws.amazon.com/compare/the-difference-between-the-difference-between-application-network-and-gateway-load-balancing/#:~:text=An%20ALB%20uses%20a%20round,targets%20in%20a%20predetermined%20manner.

-----------------------


Network ELB : TCP.. 
--> Flow Hash algorithm.
--> We CAN assign a dedicated IP address for our network ELB. Its not possible for ALB.
--> NLB is capable to handle millions req/sec.

ELB Access Logs : Logging on ELB. Destination is s3.
___________________________________________________________________

Free Tier : 750 hrs/month

==========================================================================================

--> use same SG for all your web servers. Initially open for everyone, then modify it later.
--> Use a diff SG for your load balancer. Open 80 for everyone.

SG pipeline mechanism : open port 80 on your ec2 instances SG, Instead of open for everyone, Add your Load balancer Security group.

=========================================================================================

Launch atleast 2 ec2 instances across 2 AZs.

Task : Create an ALB, and deliver webpage on One TG / Port :80. 
Test Stickyness.


Task 2 : what is Telnet and how to use telnet, test it with an ec2 instance on port 22.

telnet to google on port 443.
telnet to your ec2 instance on port 22 and test it.

================================================

Task 1 : Launch an ec2 instance, make it as webserver, 
Create an ALB, and deliver webpage on TG / Port :80. 

Launch another ec2 instance and configure apache to run on port 8080.

Task 2 : on existing LB, Add listeners on 8080 and test output on 8080.

**Open port 8080 at your ec2 SG and ELb SG.

Task 3 : Make sure you implement Pipeline mechanism.

Task 4 : Configure and deliver NLB. 

=========================================================================================

D: 13/09/24

ASG : Auto Scaling group : 

--> We can run our applicaiton with fixed Number of resources. (My app always should have 2 ec2 instances)

--> We can scale our appliucation based on the load/schedule. (when cpu usage is less i want to run my app with 2 instances, when cpu usage is moderate: 4 instance, CPU usage is High : 8 Instances) 


Pre-Req: 
1. GoldenAMI
2. ELB

ASG Creation : 
Step 1 : Create a launch Template
Step 2 : Configure ASG


Create a launch Template : You have to define all the settings you required for your ec2 instance, you are launching as part of ASG. (AMI, SG, Keypair, Instance type)

Create an ASG : What scaling method you required, desired count, in what vpc you want to run instances.

========================


ASG : Auto scaling group

1. Create a GoldenAMI
2. Create an ELB
3. Create ASG
	3.1 Create launch Template : GoldenAMI, Instancetype, Security Group, keypair
	3.2 Create scalings/asg : Manual scaling/ automatic scaling, ELB, Desired count..



1 : Create a Golden AMI
2 : Create a ELB
3 : Create a Launch template
4 : Create an ASG with Fixed (2) and test it


5 : Confiure Scheduled scaling.
6 : Configure Simple scaling (low usage scaling)
7 : Configure Versions for Launch Tempplate. 




ASG : Auto Scaling Group :

--> DYnamic (Step/Simple/TargetTracking) Load 
--> Scheduled scaling : 
--> Manual : 

Schedule Scaling : Based on given time, AWS adjust the Desired capacity on our ASG.


ScaleIN : Remove the instance from ASG
ScaleOut : Add the instances to ASG.

How ASG will choose the instance to terminate if any ScaleIN action triggered..!! 

ASG Termination policy : refer to the image.


t2.micro --> Current configuration.. 
t2.nano..??? How you can do this with 0 downtime..!! 


Create a new launch configuration/template.. Associate this with ASG. Terminate the existing instance.. Now new instance will come with updated launch config settings.
(Set Desired capacity to 2)..!!! 

==================================


Task 1 : launch an ec2 instance, install stress package and add load on your instance, Create an alarm to Automatically stop your ec2 instance when load is more than 70% for 5 min period.

sudo yum install stress -y
To know CPU count Command is "nproc"
stress --cpu 1 --timeout 900


===============================

Task 2 : Create an ASG as we discussed (AMI, Load Balancer, launch template and Asg)


Task 3 : Create alarms on ASG. Whenever CPU Usage is <= 20% for 5 min, Set your desired capacity to 1.
When CPU usage is More than >=70% for 5 min, Set your desired capacity to 3.
Add load on your ec2 instance using stress package.


Task 4 : Try Step scaling policy using shared script.


================================


Task 5 : Create an updated version in "launch template" and test the blue and green deployment method.

--> Launch an ec2 instance and make it as webserver, deliver this webpage "This is my ASG webpage".
--> Create a Golden AMI from this instance. Use this in ASG and verify.

--> Use same instance, update the web content to "This is my ASG webpage - updated".
--> Create a GOldemAMI from this instance. Update the launch template, set default version to latent one.

--> Terminate one instance and wait for another instance to launch. You should get new output also.


Task 6 : Configure Schedule scaling policy.


====================================================================================================

Security Groups place imp role in instance access.
What traffic you want to deliver from your ec2 instance to outside world, you need to open it in inbound rules. (Traffic coming from outside world to ec2 instance and ec2 is responding to that request).
Outbound : ec2 instance acessing traffic. Defaultly ec2 allowed with all incoming traffic (From ec2, we can access any protocol, any traffic from any network).

--> SGs are stateful. We need to takes care about the inbound rules.
--> Changes to the SG takes effect without any delay.
--> We can add one SG to multiple ec2 instance.
--> One instance can have multiple SGs also.
--> There is No "DENY" option in SGs.


-----------

Plecement Groups : 

--> Cluster PG : for group of ec2 instance, to get very very min latency, we can use this.
--> partition PG : We can create 7 partitions, Every part will have its dedicated power connectivity and network connectivity.
--> Spread PG : Every instance will have its own power connectivity and network connectivity.

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-strategies.html


========================================================================================

D: 16/09/24

EFS : Elastic File System : File Share : Shared Storage solution for Multiple ec2 instances. : 
--> Network File System : NFS v4.1 : Port 2049
--> Support only Linux OS 
--> No Pre Provisioning required.
--> Add entry in "/etc/fstab" file.  Get entry info from "/etc/mtab" file


mkdir instance1

sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-084f2131397e5b3d2.efs.ap-south-1.amazonaws.com:/ instance1


Install httpd and mount efs to /var/www/html/ path

sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-084f2131397e5b3d2.efs.ap-south-1.amazonaws.com:/ /var/www/html/


==> For windows OS we can use FSx, Works with SMB Protocol (Server message block)

_______________________________________________________________________________________

--> Create a security group and open NFS protocol. 
			--> Open for entire VPC IP address
			--> Open for ec2 instance private IP addresses
		** --> Open for ec2 instance Security group (pipeline mechanism) (highly Recommened)
		   --> As a last option, if no above option is working, open for Everyone. (Not recommended)


Task : Create EFS and Mount it to multiple ec2 instances. Deliver Web Content to both the instances from EFS.


Task : 
1. Launch an ec2 instance, connect to it, 
2. Create EFS.. 
3. Install httpd in your ec2 instance.. 
4. Mount EFS to /var/www/html/ and create index.html...  
5. make it as perm mount. get EFS entry from /etc/mtab and write to to /etc/fstab
6. Test your ec2 instance webpage.

7. Stop above ec2 instance and create a goldenAMI.
8. launch a new ec2 instance from GoldemAMi, test your webpage. (**)

Then Proced to below steps
==> Now create a GOLDENAMI.. or use Step 7 GAMI.. 
==> Create a Load Balancer
==> Configure ASG with this GOLDENAMI.. Connect to any of the ec2 instance, modify the content.. this modification should reflect in all instance.. 

==================================

Instance Stop protection : protect instance from accidental stops.
Instance Termination protection : protect instance from accidental Termination.
Shutdown behaviour : If we initiate a shutdown operation from/at OS, What should happend to our ec2 instance.
	--> Stop
	--> Terminate
	
==========================================================================================

D: 17/09/2024


AWS CLI : 


Step 1 : Download and install aws cli tools in your laptop. To verify installation run below comamnd

aws --version

Step 2 : Configure AWS CLI, FOr that we need AccessKeyID and SecretAccessKey.

--> Create an IAM user.
--> Then navigate to "Credentials" and generate keys.


aws ec2 describe-instances --instance-ids i-0f864a025fd09ddd9


IAM User : programatic Access : AccesskeyID and SecretAccesskey : AWS CLI.. 3rd, cdk/sdk

https://aws.amazon.com/cli

aws --version			--> Tells us what cli version is installed.

configure the aws cli: 
aws configure
AccesskeyID:
SecretAccesskey:
Region:
output :


aws servicename commands

aws s3 ls			--> List all the s3 buckets
aws s3 ls s3://avinash.bucket	--> list objects from the s3 bucket
aws s3 ls avinash.bucket

aws s3 cp/sync sourcepath destinationpath

aws s3 mb s3://avinash.bucket.1 --region ap-south-1

aws s3 cp s3://avinash.bucket s3://avinash.bucket.1 --recursive

aws s3 sync s3://avinash.bucket s3://avinash.bucket.1

presign

aws s3 presign s3://bucketname/objectname --expire 60

aws s3 presign s3://avinash.bucket.1/s3.txt --expire 30

___

https://docs.aws.amazon.com/cli/latest/reference/

__

https://awsclibuilder.com/home

___

--profile : We can access multiple AWS accounts from cli using profile option.

aws s3 ls ==> THis will pick default profile configured cred.
aws s3 ls --profile uat ==> THis will pick UAT configured cred.

aws configure --profile uat
AccessKey
SecretAccessKey
Region
output


--debug ==> helps us to identify the process / where the issue occured.

Credentials path in windows : C:/users/yourusername/.aws/ Enable Hidden directory view, 

___________________________


Task : Launch an ec2 instance using CLI.  (ami id, instance-type, subnet-id, security group id, keypair, count) (Example 4: To launch an instance and add tags on creation)

Task 2 : Stop that ec2 instance using CLI comamnds.

Task 3 : Start the same ec2 instance using cli.

Task 4 : Create 2 IAM users with programaticAccess. 
User1: S3FullAccess
user2: ec2FullAccess

Configure both of the users in your laptop with profile.

--profile s3user
--profile ec2user


aws ec2 describe-instances --profile ec2user --> should list ec2 instance
aws s3 ls --profile ec2user --> should not list s3 buckets

aws ec2 describe-instances --profile s3user --> should not list ec2 instances
aws s3 ls --profile s3user --> should list s3 buckets

==========================

In real environment, In our Code, we dont hardcode CLI credentials, 
In our ec2 instances, we dont store CLI Cred.. 

==> Most of the times, we use Roles, Roles are more secure compare to CLI.Roles provides temporary generated credentails, this will change/rorate automatically.

Step 1: create a Role and attach to your ec2 instance. (role also supports: ec2, rds, ecs, lambda, step function .....)

Step 2 : Login to your ec2 instance and try to access the services (Role required a policy, whatever the polocies you atatch to role, those services only we can access from ec2 instance)


Name of role (S3FullRole) : Where you attach/use (EC2 Instance) --> What permisisons you nrequired (s3fullaccess) --> Review and create.  ==> Go to ec2 instance and attach the role to your instance.



=================================


Task 1 : Launch an ec2 instance and Configure a role to access s3 data. (don't configure accesskey/secretkey.. use roles)

Task 2 : 
1. Create a sample webpages (index.html & status.html) and Upload a webtemplates to an s3 bucket.. 
2. launch an ec2 instance, while launching the instance, make your instance as webserver using userdata.
3. While using userdata,  copy all the webcontent from s3 bucket to DocumentRoot path (/var/www/html/). Perform using "userdata".
4. make sure you attach an IAM role to your ec2 instance that can provide s3 access.

#!/bin/bash
yum install httpd -y
service httpd start
chkconfig httpd on
#copy data from s3 to ec2		(--recursive)

Task 3 (Optional : Fresher.. Mandatory: For Exp candidates) :  Create an IAM user in Account 1.. Allow this user to switch to "Account 2".. When he switch to account 2, Allow him to perform only "S3FullAccess".

Refer : https://www.youtube.com/watch?v=sZiiB4yF0VY

==========================================================================================

D: 18/09/2024

Eventbridge

--> Event Driven process
--> Scheduled process
--> Trigger both

0 18 ? * MON-FRI *

Event Bridge : 

{"version":"0","id":"04bdca71-dc52-8e8c-f5a5-c8ed45d9d775","detail-type":"EC2 Instance State-change Notification","source":"aws.ec2","account":"501170964283","time":"2024-07-24T03:04:02Z","region":"ap-south-1","resources":["arn:aws:ec2:ap-south-1:501170964283:instance/i-0dc84d88fc003f776"],"detail":{"instance-id":"i-0dc84d88fc003f776","state":"stopped"}}


 Sample Event : 

 INPUT PATH:

 {"instance-id":"$.detail.instance-id", "state":"$.detail.state", "time":"$.time", "region":"$.region", "account":"$.account"}

 INPUT TEMPLATE: 

 "At <time>, Status of your EC2 instance <instance-id> in the AWS Region <region> has changed to <state>."
 

https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html
https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-create-rule-schedule.html#eb-cron-expressions


==========================================================================================

Task 1 : Configure Eventbridge to stop an ec2 instance at a particular time using Crontab. (9:15 Am)

Task 2 : Configure to stop an ec2 instance after 5 minutes, trigger an email with custom email format.

Task 3 : Configure to get an alert when someone deleted an s3 bucket. (Enable Data trail)

==========================================================================================

D: 19/09/2024

Systems Manager run command :
--> All instance must associated with "SSM ROle". 
--> OS level, Every instance should have an SSM agent.  
--> Using Tags, We can filter the instances. / We can choose instances manually. 
--> Make sure to attach an IAM role.

Without log-in to ec2 instance, we can run command, we can perform activities using SSM "run command" option.


System Manager Session Manager : We can connect to our ec2 instance, without opening port 22, without bastian host.

System manager Fleet Manager : To connect to windows ec2 instance using GUI, we can use fleet manager option.

--------

Task : How to recover a Windows instance administraor password if we loss the keypair.
AWSSupport-RunEC2RescueForWindowsTool

Steps to test: 
1. Launch a windows instance and connect to it using "keypair" password.
2. Change Administrator's password and forgot it, Then disconnect from the server.
3. Attach an IAM role, use "run comamnd - EC2 Rescue for Windows Tool"
4. Password stores under "Parameter store", Use it and connect to your instance.


Task : Make linux ec2 instance as webserver without logging to OS level.

Task : Change the timezone of an windows ec2 instance using ssm run command. (tzutil /s "India Standard Time")

<script>
tzutil /s "India Standard Time"
</script>

Task : Install tree package in linux instances without logging into. Using SSM Run Command.

========================================

Cloudwatch Dashboards: central location to monitor multiple resources usage. You can add individual resources metric graphs into a single dashboard.

========================================

Platform : Windows
Platform : Linux

d : Dev
Q : QA
s : Staging / NonProd
u : uat 
p : production
Dr : DR Resource

wi : Windows
li : Linux

wt : app code (World Trade), TW (Trade World) : app code

C1/C2 : Client id 

IN : Internal Servers (not client facing servers)

01/02 : S.N for Server when we have multiple

Naming Standards 
P-WI-WT-AD :   
P-LI-WT-HD :
S-Li-ap2-c1 : 

P-WI-IN-AD-01
P-WI-IN-AD-02
P-WI-IN-EX-01
P-WI-WT-C1-03
P-LI-WT-C2-01
P-LI-WT-C2-02
P-LI-WT-IN-01


PWIWTC202
ULIWTC201


====================================================================================================

D: 20/09/2024

ElasticBeanstalk : It provides preconfigured platforms. : Its a PaaS (platform as a Service)
--> Python, java, go, ruby, php, .net, Docker
--> We can deploy/upload our code to this platform. 
--> AWS Creates ELB, ASG automatically for our instances, Based on the preset option we select.
--> Less customisations at OS level, We cannot deliver multiple applications.

====================================================================

Metadata : metadata means, data about the data. 
We are using ec2 instance to deliver some data/webpage. We do have some info about the ec2 instance.. 
By using metadata url, we can get info about the ec2 instance.

Linux : curl http://169.254.169.254/latest/meta-data/

open browser and enter http://169.254.169.254/latest/user-data/

ami-id
ami-launch-index
ami-manifest-path
block-device-mapping/
events/
hostname
identity-credentials/
instance-action
instance-id
instance-life-cycle
instance-type
local-hostname
local-ipv4
mac
managed-ssh-keys/
metrics/
network/
placement/
profile
public-hostname
public-ipv4
public-keys/
reservation-id
security-groups
services/


Status Checks on ec2 instance : we have 2 types of status checks. When any instance is launched, aws performs 2 status checks.
1. System Status check : underlying hardware status check. Healthy/unhealthy. 
	fix : Perform stop and start multiple times. Otherwise, contact aws.
2. Instance status check : os level checks, Boot health status, Volume size check.
	fix : First reboot.. Then verify boot logs. "get Systemn logs" and inspect for the issue.
		  We can perform "replace root volume" operation.






===============================================

Instance store volumes : We don't use this in real environments.   (NO FREE TIER ELIGIBILTY)
	--> Also called as Ephemeral storages (Temporary storage).
	--> We cannot STOP/Start the instance.
	--> Storage will be delivered from underlying host/physical resources.
	--> If required, we can reboot. We don't loss any data.
	--> If underlying h/w failure happens, we'll loss all the data.
	--> Accidental stop/start occured, We will loss all data.

==================================

Instance Isolation : https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRjr993FsAyS65uL4QPbGu8n_JcB6Fwq6jDylWglIapsQQjHfbcbir83OT-I-_a-nhvvo8&usqp=CAU

VMWare: ESXi
Microsoft ; Hyper-V
AWS : Support XEN, AWS OWned "Nitro"

Baremetal hypervisor : On top of Hardware, a hypervisor runs, we can laiunch guestOS on top of hypervisor.
HostBased hypervisor : On top of hardware, a host OS runs (win 10/11), on top of it, we need to install hypervisor, then we can run GuestOS.

==================================

Dedicated and Shared tenancy :
--> Shared tenancy : underlying hardware shared with multiple customers.
--> Dedicated tenancy:
	--> Dedicated instance : Dedicated instance provided by aws. No control on backend process.
	--> Dedicated host : We can apply licenses at underlying physical resources. Also, we can launch multiple instances on a dedicated host.



https://www.youtube.com/playlist?list=PLneBjIzDLECkZXsv7g-YsP6bBteTpTgLC

go though ec2 Interview video
